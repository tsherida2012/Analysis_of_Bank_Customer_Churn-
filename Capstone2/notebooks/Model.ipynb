{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03016042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e33d2d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data = pd.read_csv('cleaned-A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e4bd231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[37524,  1609],\n",
       "        [ 8235,  2143]], dtype=int64),\n",
       " 0.8011754963543455,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.82      0.96      0.88     39133\\n           1       0.57      0.21      0.30     10378\\n\\n    accuracy                           0.80     49511\\n   macro avg       0.70      0.58      0.59     49511\\nweighted avg       0.77      0.80      0.76     49511\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Selecting additional features\n",
    "features = ['Age', 'CreditScore', 'Balance', 'NumOfProducts']\n",
    "X = bank_data[features]\n",
    "y = bank_data['Exited']\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the model\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "conf_matrix, acc_score, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6fc4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Performance\n",
      "-------------------------------\n",
      "Accuracy: 0.7928541132273637\n",
      "Confusion Matrix:\n",
      "             Predicted: No  Predicted: Yes\n",
      "Actual: No           34544            4589\n",
      "Actual: Yes           5667            4711\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87     39133\n",
      "           1       0.51      0.45      0.48     10378\n",
      "\n",
      "    accuracy                           0.79     49511\n",
      "   macro avg       0.68      0.67      0.67     49511\n",
      "weighted avg       0.79      0.79      0.79     49511\n",
      "\n",
      "\n",
      "\n",
      "Random Forest Model Performance\n",
      "-------------------------------\n",
      "Accuracy: 0.8253923370564117\n",
      "Confusion Matrix:\n",
      "             Predicted: No  Predicted: Yes\n",
      "Actual: No           35920            3213\n",
      "Actual: Yes           5432            4946\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89     39133\n",
      "           1       0.61      0.48      0.53     10378\n",
      "\n",
      "    accuracy                           0.83     49511\n",
      "   macro avg       0.74      0.70      0.71     49511\n",
      "weighted avg       0.81      0.83      0.82     49511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fitting Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Fitting Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions with Decision Tree\n",
    "dt_y_pred = decision_tree.predict(X_test_scaled)\n",
    "\n",
    "# Making predictions with Random Forest\n",
    "rf_y_pred = random_forest.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating Decision Tree\n",
    "dt_conf_matrix = confusion_matrix(y_test, dt_y_pred)\n",
    "dt_acc_score = accuracy_score(y_test, dt_y_pred)\n",
    "dt_class_report = classification_report(y_test, dt_y_pred)\n",
    "\n",
    "# Evaluating Random Forest\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_y_pred)\n",
    "rf_acc_score = accuracy_score(y_test, rf_y_pred)\n",
    "rf_class_report = classification_report(y_test, rf_y_pred)\n",
    "\n",
    "# Printing the Decision Tree results\n",
    "print(\"Decision Tree Model Performance\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"Accuracy:\", dt_acc_score)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(dt_conf_matrix, index=['Actual: No', 'Actual: Yes'], columns=['Predicted: No', 'Predicted: Yes']))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(dt_class_report)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Printing the Random Forest results\n",
    "print(\"Random Forest Model Performance\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"Accuracy:\", rf_acc_score)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(rf_conf_matrix, index=['Actual: No', 'Actual: Yes'], columns=['Predicted: No', 'Predicted: Yes']))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(rf_class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01f7db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with Entropy\n",
      "Accuracy: 0.7948940639453859\n",
      "Confusion Matrix:\n",
      "             Predicted: No  Predicted: Yes\n",
      "Actual: No           34622            4511\n",
      "Actual: Yes           5644            4734\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87     39133\n",
      "           1       0.51      0.46      0.48     10378\n",
      "\n",
      "    accuracy                           0.79     49511\n",
      "   macro avg       0.69      0.67      0.68     49511\n",
      "weighted avg       0.79      0.79      0.79     49511\n",
      "\n",
      "\n",
      "Decision Tree with Gini Impurity\n",
      "Accuracy: 0.7928541132273637\n",
      "Confusion Matrix:\n",
      "             Predicted: No  Predicted: Yes\n",
      "Actual: No           34544            4589\n",
      "Actual: Yes           5667            4711\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87     39133\n",
      "           1       0.51      0.45      0.48     10378\n",
      "\n",
      "    accuracy                           0.79     49511\n",
      "   macro avg       0.68      0.67      0.67     49511\n",
      "weighted avg       0.79      0.79      0.79     49511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Defining the models\n",
    "dt_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "dt_gini = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "\n",
    "# Fitting the models\n",
    "dt_entropy.fit(X_train_scaled, y_train)\n",
    "dt_gini.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "dt_entropy_pred = dt_entropy.predict(X_test_scaled)\n",
    "dt_gini_pred = dt_gini.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the models\n",
    "# Entropy\n",
    "entropy_conf_matrix = confusion_matrix(y_test, dt_entropy_pred)\n",
    "entropy_acc_score = accuracy_score(y_test, dt_entropy_pred)\n",
    "entropy_class_report = classification_report(y_test, dt_entropy_pred)\n",
    "\n",
    "# Gini\n",
    "gini_conf_matrix = confusion_matrix(y_test, dt_gini_pred)\n",
    "gini_acc_score = accuracy_score(y_test, dt_gini_pred)\n",
    "gini_class_report = classification_report(y_test, dt_gini_pred)\n",
    "\n",
    "# Printing results\n",
    "print(\"Decision Tree with Entropy\")\n",
    "print(\"Accuracy:\", entropy_acc_score)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(entropy_conf_matrix, index=['Actual: No', 'Actual: Yes'], columns=['Predicted: No', 'Predicted: Yes']))\n",
    "print(\"Classification Report:\")\n",
    "print(entropy_class_report)\n",
    "\n",
    "print(\"\\nDecision Tree with Gini Impurity\")\n",
    "print(\"Accuracy:\", gini_acc_score)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(gini_conf_matrix, index=['Actual: No', 'Actual: Yes'], columns=['Predicted: No', 'Predicted: Yes']))\n",
    "print(\"Classification Report:\")\n",
    "print(gini_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c471f481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Model Performance\n",
      "Accuracy: 0.8484175233786432\n",
      "Confusion Matrix:\n",
      "             Predicted: No  Predicted: Yes\n",
      "Actual: No           36847            2286\n",
      "Actual: Yes           5219            5159\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     39133\n",
      "           1       0.69      0.50      0.58     10378\n",
      "\n",
      "    accuracy                           0.85     49511\n",
      "   macro avg       0.78      0.72      0.74     49511\n",
      "weighted avg       0.84      0.85      0.84     49511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Defining the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Fitting the model\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "gb_pred = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the model\n",
    "gb_conf_matrix = confusion_matrix(y_test, gb_pred)\n",
    "gb_acc_score = accuracy_score(y_test, gb_pred)\n",
    "gb_class_report = classification_report(y_test, gb_pred)\n",
    "\n",
    "# Printing results\n",
    "print(\"Gradient Boosting Model Performance\")\n",
    "print(\"Accuracy:\", gb_acc_score)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(gb_conf_matrix, index=['Actual: No', 'Actual: Yes'], columns=['Predicted: No', 'Predicted: Yes']))\n",
    "print(\"Classification Report:\")\n",
    "print(gb_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9008c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Ensemble Model Performance\n",
      "Accuracy: 0.8491648320575226\n",
      "Confusion Matrix:\n",
      "             Predicted: No  Predicted: Yes\n",
      "Actual: No           36892            2241\n",
      "Actual: Yes           5227            5151\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     39133\n",
      "           1       0.70      0.50      0.58     10378\n",
      "\n",
      "    accuracy                           0.85     49511\n",
      "   macro avg       0.79      0.72      0.74     49511\n",
      "weighted avg       0.84      0.85      0.84     49511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "# Define meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create the stacking ensemble model\n",
    "stacked_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "stacked_pred = stacked_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "stacked_conf_matrix = confusion_matrix(y_test, stacked_pred)\n",
    "stacked_acc_score = accuracy_score(y_test, stacked_pred)\n",
    "stacked_class_report = classification_report(y_test, stacked_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Stacked Ensemble Model Performance\")\n",
    "print(\"Accuracy:\", stacked_acc_score)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(stacked_conf_matrix, index=['Actual: No', 'Actual: Yes'], columns=['Predicted: No', 'Predicted: Yes']))\n",
    "print(\"Classification Report:\")\n",
    "print(stacked_class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4949f",
   "metadata": {},
   "source": [
    "**The Stacked Ensemble Model** has the highest accuracy and performs slightly better overall than the Gradient Boosting model, with similar precision, recall, and F1-scores for predicting Class 1. This suggests it might be the most reliable model, combining the strengths of Random Forest, Gradient Boosting, and Decision Trees effectively.\n",
    "\n",
    "**Precision for Class 1:** The Stacked Ensemble also has the highest precision for predicting Class 1, tied closely with the Gradient Boosting model. Higher precision is crucial if the cost of false positives (incorrectly predicting that a customer will exit when they will not) is high.\n",
    "\n",
    "**In the Random Forest model**, the recall for Class 1 is the highest, albeit only slightly better than the Stacked Ensemble and Gradient Boosting models. High recall is important if missing out on actual churners (false negatives) is more detrimental.\n",
    "\n",
    "Given the slight improvements in performance metrics and the balanced approach of handling different errors (precision and recall), the Stacked Ensemble Model appears to be the best choice. It effectively leverages the individual strengths of various models, improving the overall decision-making process.\n",
    "\n",
    "**The Stacked Ensemble Model** is more complex and may require more computational resources and time to train than simpler models like Logistic Regression or a single Decision Tree.\n",
    "\n",
    "We must also consider the interpretability of your model. Ensemble methods, especially stacking, can be harder to interpret compared to simpler models.\n",
    "\n",
    "In a business context, where both the costs of false positives and false negatives can be significant (such as in customer churn prediction), it is typically the prefered a model that balances precision and recall while providing the highest overall accuracy. Therefore, implementing the Stacked Ensemble Model will be the best strategy provided the computational resources are adequate for the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c2e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
